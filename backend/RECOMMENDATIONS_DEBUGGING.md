# Recommendations Debugging Guide

## Issue: "No Optimization Opportunities Found" Always Showing

### Root Cause Identified âœ…

**Problem:** Azure LLM endpoint was returning `null` for recommendations instead of an array.

**Location:** `backend/app/api/v1/endpoints/llm.py` (Line 169)

**Why it happened:**
1. `run_llm_vm()` and `run_llm_storage()` return a **single dict** `{}` or `None`
2. API endpoint checked: `isinstance(result, list)`
3. When result was a dict (not list), it set `recommendations=None`
4. Frontend received: `{"recommendations": null, ...}`
5. Frontend parsing: `JSON.parse(null)` â†’ empty array `[]`
6. UI displayed: "No optimization opportunities found"

**The Fix Applied:**
```python
# Convert single dict result to list for consistent frontend handling
if result is not None:
    result_list = [result] if isinstance(result, dict) else result
else:
    result_list = []

return LLMResponse(
    ...
    recommendations=json.dumps(result_list) if result_list else None,
    ...
)
```

---

## How to Debug Recommendations Issues

### 1. Check Backend Logs

Look for these log messages in the backend console:

**VM Analysis:**
```
ðŸ”Ž Running VM LLM for {schema_name} from {start_str} to {end_str}
âš ï¸ No VM data found for the requested date range / resource.
âœ… LLM analysis complete! Returning recommendation.
vm recommendation generated by LLM: {recommendation}
```

**Storage Analysis:**
```
ðŸ”Ž Running Storage LLM for {schema_name} from {start_str} to {end_str}
âš ï¸ No storage account data found for the requested date range / resource.
âœ… LLM analysis complete! Returning recommendation.
```

**Empty Response:**
```
Empty LLM response for compute resource {resource_id}
Could not extract JSON from LLM output for compute resource {resource_id}
Error decoding JSON (after extraction) for compute resource {resource_id}
```

### 2. Check Database Data

**Verify metrics exist:**
```sql
-- Check VM metrics
SELECT COUNT(*) FROM {schema}.gold_azure_fact_vm_metrics
WHERE timestamp >= 'YYYY-MM-DD'
  AND timestamp <= 'YYYY-MM-DD';

-- Check Storage metrics
SELECT COUNT(*) FROM {schema}.gold_azure_fact_storage_metrics
WHERE date_key BETWEEN 'YYYY-MM-DD' AND 'YYYY-MM-DD';

-- Check cost data
SELECT COUNT(*), SUM(billed_cost)
FROM {schema}.gold_azure_fact_cost
WHERE charge_period_start >= 'YYYY-MM-DD';
```

**Verify resource dimension data:**
```sql
SELECT resource_id, resource_name, service_category
FROM {schema}.gold_azure_resource_dim
WHERE service_category IN ('Compute', 'Storage')
LIMIT 10;
```

### 3. Check API Response

**Using browser DevTools (Network tab):**
1. Open DevTools â†’ Network tab
2. Click "Run Analysis"
3. Find POST request to `/llm/azure/{project}`
4. Check Response:

**Expected structure:**
```json
{
  "status": "success",
  "cloud": "azure",
  "recommendations": "[{...}]",  // JSON STRING containing array
  "timestamp": "2025-01-17T..."
}
```

**Problem indicators:**
- `"recommendations": null` â†’ Backend returning None (no data or error)
- `"recommendations": "{}"` â†’ Single dict instead of array (THIS WAS THE BUG - NOW FIXED)
- `"recommendations": "[]"` â†’ Empty array (no LLM recommendations generated)

### 4. Check Frontend Console

**Browser Console â†’ Look for:**
```
API Error fetching azure vm: ...
Failed to load VM analysis. Please check the backend service.
```

### 5. Test LLM Integration Manually

Create a test script to verify LLM is working:

```python
# test_llm.py
from app.ingestion.azure.llm import run_llm_vm
from app.ingestion.azure.postgres_operation import connection

@connection
def test_vm_recommendations(conn):
    result = run_llm_vm(
        conn,
        schema_name="your_schema",
        start_date="2025-01-01",
        end_date="2025-01-31",
        resource_id=None  # Or specific resource ID
    )
    print(f"Result type: {type(result)}")
    print(f"Result: {result}")
    return result

if __name__ == "__main__":
    test_vm_recommendations()
```

---

## Common Issues & Solutions

### Issue 1: Empty Database (No Metrics)

**Symptoms:**
- Backend logs: "No VM/storage data found"
- Database queries return 0 rows

**Solution:**
- Verify data ingestion is running
- Check CloudWatch metrics collection
- Verify schema name matches project name

### Issue 2: LLM Returning "No Optimization Needed"

**Symptoms:**
- Data exists in database
- LLM responds but says resources are well-optimized

**Solution:**
- This is actually a valid response if resources ARE optimized
- The LLM prompt instructs it to be conservative
- Check if actual utilization is high (>80% CPU, etc.)

### Issue 3: LLM JSON Parsing Errors

**Symptoms:**
- Backend logs: "Could not extract JSON from LLM output"
- Backend logs: "Error decoding JSON"

**Solution:**
- Check Azure OpenAI API is accessible
- Verify AZURE_OPENAI_KEY is valid
- Check if model is available (deployment exists)
- Review LLM prompt for correct JSON schema

### Issue 4: Date Range Issues

**Symptoms:**
- No data even though metrics exist
- Database has data but queries return empty

**Solution:**
- Ensure date range includes data
- Check timezone mismatches
- Verify date format: YYYY-MM-DD

### Issue 5: Frontend Shows "Error: Failed to load..."

**Symptoms:**
- API call fails
- Network error in DevTools

**Solution:**
- Check backend is running
- Verify project exists in database
- Check schema_name resolution
- Review backend error logs

---

## Testing Recommendations End-to-End

### 1. Prepare Test Data

```sql
-- Insert test VM metrics
INSERT INTO {schema}.gold_azure_fact_vm_metrics (
    resource_id, metric_name, value, timestamp
) VALUES
    ('/subscriptions/.../vm-test', 'Percentage CPU', 15.5, '2025-01-15 10:00:00'),
    ('/subscriptions/.../vm-test', 'Percentage CPU', 18.2, '2025-01-15 11:00:00'),
    ('/subscriptions/.../vm-test', 'Network In', 1024000, '2025-01-15 10:00:00');

-- Insert test cost data
INSERT INTO {schema}.gold_azure_fact_cost (
    resource_id, billed_cost, charge_period_start, charge_period_end
) VALUES
    ('/subscriptions/.../vm-test', 250.00, '2025-01-01', '2025-01-31');
```

### 2. Make API Request

```bash
curl -X POST "http://localhost:8000/llm/azure/your-project" \
  -H "Content-Type: application/json" \
  -d '{
    "resource_type": "vm",
    "start_date": "2025-01-01T00:00:00",
    "end_date": "2025-01-31T23:59:59"
  }'
```

### 3. Expected Response

```json
{
  "status": "success",
  "cloud": "azure",
  "resource_type": "vm",
  "recommendations": "[{\"resource_id\":\"/subscriptions/.../vm-test\",\"recommendations\":{\"effective_recommendation\":{\"text\":\"Downsize VM...\",\"saving_pct\":35}}}]"
}
```

### 4. Frontend Display

- Should show 1 recommendation card
- Severity badge (High/Medium/Low)
- Saving percentage
- Monthly forecast
- Detailed steps

---

## Environment Variables Checklist

Ensure these are set in `.env`:

```bash
# Database
DB_USER_NAME=postgres
DB_PASSWORD=***
DB_HOST_NAME=localhost
DB_PORT=5432
DB_NAME=finops

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
AZURE_OPENAI_KEY=***
AZURE_DEPLOYMENT_NAME=gpt-4
AZURE_OPENAI_VERSION=2024-02-15-preview
```

---

## Success Indicators

âœ… **Everything Working:**
1. Backend logs show: "âœ… LLM analysis complete!"
2. API returns: `"recommendations": "[{...}]"` (non-null, non-empty)
3. Frontend displays recommendation cards
4. Cards show specific optimization steps
5. Saving percentages are calculated
6. Monthly forecasts are displayed

---

## Quick Diagnostic Checklist

- [ ] Backend server is running
- [ ] Database connection works
- [ ] Schema exists and has data
- [ ] Date range includes metric data
- [ ] Azure OpenAI credentials are valid
- [ ] LLM deployment is accessible
- [ ] Project name resolves to schema
- [ ] Resource type is supported (vm, storage)
- [ ] Frontend can reach backend API
- [ ] Browser console shows no errors

---

**Last Updated:** January 17, 2025
**Bug Fixed:** Azure endpoint now properly wraps single dict results in array
**Commit:** 29c8210
